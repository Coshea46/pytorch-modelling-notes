
# Why 

In general, it makes it so that you can just use the built in torch functions for:

- Swapping between CPU and GPU
- Optimizers (e.g. Stochastic Gradient Descent, ADAM)
- Training (by giving you easy access to autograd computational trees)
- Switching between training and evaluation modes dynamically

